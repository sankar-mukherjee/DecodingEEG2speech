{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\projects\\\\current\\\\listen_italian_motor_entrainment\\\\analysis\\\\python\\\\acoustic-articulatory'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import librosa\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "\n",
    "base_dir = os.getcwd()\n",
    "base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "data_path = os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "raw_fname = data_path+ '\\exp\\exp_running_scirpt\\olm_stimuli_normalRepeatTwice.mat'\n",
    "data = scipy.io.loadmat(raw_fname)\n",
    "raw_fname = data_path+ '/analysis/behaviour/data/palate_trace_only_stimuli_new.mat'\n",
    "palate_trace = scipy.io.loadmat(raw_fname)\n",
    "palate_trace = palate_trace['palate_trace']\n",
    "\n",
    "\n",
    "filenames = data['data']['filename'][0][0][0]\n",
    "speech = data['data']['speech'][0][0][0]\n",
    "fs = data['data']['fs'][0][0][0][0]\n",
    "#lab = data['data']['lab'][0][0][0]\n",
    "ema = data['data']['ema'][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# add context to input frames\n",
    "frame_context = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# extract features\n",
    "n_mfcc = 13\n",
    "resample_freq = 100\n",
    "\n",
    "\n",
    "def rolling_window(a, window):\n",
    "    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n",
    "    strides = a.strides + (a.strides[-1],)\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)\n",
    "\n",
    "\n",
    "\n",
    "audio_feat = []\n",
    "ema_feat   = []\n",
    "for i in range(0,len(filenames)):\n",
    "    # meta data\n",
    "    filename = filenames[i][0].replace('.wav','')\n",
    "    \n",
    "    a = filename.split('_')\n",
    "    if(a[0]=='n'):\n",
    "        condition = 2\n",
    "    elif(int(a[2])>5):\n",
    "        condition = 3\n",
    "    else:\n",
    "        condition = 1\n",
    "    \n",
    "    # downsample ema to 100 hz\n",
    "    A = []\n",
    "    a = ema[i].shape[1]/400 # Number of seconds in signal X\n",
    "    a = a*resample_freq     # Number of samples to downsample\n",
    "    for j in range(0,ema[i].shape[0]):\n",
    "        A.append(scipy.signal.resample(ema[i][j,:], int(np.ceil(a))))\n",
    "    A = np.stack(A)\n",
    "    \n",
    "    # mfcc\n",
    "    mfcc = librosa.feature.mfcc(y=speech[i].flatten(), sr=fs,\n",
    "                                hop_length=int(0.010*fs), n_fft=int(0.025*fs), n_mfcc=n_mfcc)\n",
    "    \n",
    "    \n",
    "    if(mfcc.shape[1]>A.shape[1]):\n",
    "        mfcc = mfcc[:,:A.shape[1]]            \n",
    "    elif(mfcc.shape[1]<A.shape[1]):\n",
    "        A = A[:,:mfcc.shape[1]]\n",
    "    \n",
    "    mfcc_delta = librosa.feature.delta(mfcc)\n",
    "    mfcc_delta2 = librosa.feature.delta(mfcc, order=2)    \n",
    "    a = np.vstack((mfcc,mfcc_delta,mfcc_delta2))\n",
    "\n",
    "    # adding context to frames\n",
    "    b = np.pad(a,((0,0),(int((frame_context-1)/2), int((frame_context-1)/2))), 'constant')\n",
    "    if not(frame_context==0):\n",
    "        b = rolling_window(b, frame_context)\n",
    "        b = np.swapaxes(b,2,1)\n",
    "        b = b.reshape(-1, b.shape[-1])\n",
    "    \n",
    "    audio_feat.append(b)\n",
    "    ema_feat.append(A)\n",
    "    \n",
    "    print(i,end=' ')\n",
    "    clear_output\n",
    "\n",
    "audio_feat = np.hstack(audio_feat)\n",
    "ema_feat = np.hstack(ema_feat)\n",
    "audio_feat=audio_feat.astype('f')\n",
    "ema_feat=ema_feat.astype('f')\n",
    "\n",
    "save_path = data_path + '/analysis/python/data/extracted_features/mfcc_contextSize-'+str(frame_context)+'.npy'\n",
    "np.save(save_path,audio_feat)\n",
    "save_path = data_path + '/analysis/python/data/extracted_features/raw_ema.npy'\n",
    "np.save(save_path,ema_feat)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
